@article{greenwade93,
    author  = "George D. Greenwade",
    title   = "The {C}omprehensive {T}ex {A}rchive {N}etwork ({CTAN})",
    year    = "1993",
    journal = "TUGBoat",
    volume  = "14",
    number  = "3",
    pages   = "342--351"
}
@online{Hawk-eye,
    title = "Hawk-eye.",
    url  = "https://www.hawkeyeinnovations.com",
    
}
@online{var,
    title = "The video assistant referee.",
    url  = "https://www.fifa.com/technical/football-technology/standards/video-assistant-referee",
    
}
@online{sevensix,
    title = "Sevensix coaching",
    url = "https://sevensixtennis.com",

}
@INPROCEEDINGS{8379085,
  author={Tahan, Oussama and Rady, Mohamad and Sleiman, Nabil and Ghantous, Milad and Merhi, Zaher},
  booktitle={2018 19th IEEE Mediterranean Electrotechnical Conference (MELECON)}, 
  title={A computer vision driven squash players tracking system}, 
  year={2018},
  volume={},
  number={},
  pages={155-159},
  doi={10.1109/MELCON.2018.8379085}}
@INPROCEEDINGS{9289223,
  author={Lee, JungSoo and Moon, Sungwon and Nam, Do-Won and Lee, Jiwon and Oh, Ah Reum and Yoo, Wonyoung},
  booktitle={2020 International Conference on Information and Communication Technology Convergence (ICTC)}, 
  title={A Study on Sports Player Tracking based on Video using Deep Learning}, 
  year={2020},
  volume={},
  number={},
  pages={1161-1163},
  doi={10.1109/ICTC49870.2020.9289223}}


@inproceedings{10.1145/3606038.3616164,
author = {Nakabayashi, Takuya and Kondo, Akimasa and Higa, Kyota and Girbau, Andreu and Satoh, Shin'ichi and Saito, Hideo},
title = {Event-Based High-Speed Ball Detection in Sports Video},
year = {2023},
isbn = {9798400702693},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3606038.3616164},
doi = {10.1145/3606038.3616164},
abstract = {Ball detection in sports, particularly in fast-paced games like volleyball, where the ball is constantly in high motion, presents a significant challenge for game analysis and automated sports broadcasting. Conventional camera-based ball detection faces issues, such as motion blur, in high-speed ball movement scenes. To address these challenges, we propose a deep learning-based method for detecting balls using event cameras. Event cameras, also known as dynamic vision sensors, operate differently from traditional cameras. Instead of capturing frames at fixed intervals, they record individual pixel-level luminance changes, referred to as events. This unique feature enables event cameras to provide precise temporal information with low latency. Our proposed method transforms sparse events into an image format, enabling the use of current deep-learning architectures for object detection. Given the limited amount of events available for training an object detector, we generate synthetic events from RGB frames. This approach reduces the need for extensive annotation and ensures sufficient data availability. Experimental results confirm that our proposed method can detect balls that are undetectable in RGB frames and outperform existing methods that utilize event-based ball detection. Moreover, we conducted tests to verify our method's ability to detect balls in real events, not just synthetic ones. These results demonstrate that our proposed method opens up new possibilities in sports ball detection.},
booktitle = {Proceedings of the 6th International Workshop on Multimedia Content Analysis in Sports},
pages = {55–62},
numpages = {8},
keywords = {synthetic datasets, ball detection, event camera},
location = {Ottawa ON, Canada},
series = {MMSports '23}
}
@INPROCEEDINGS{need_for_speed,
  author={Galoogahi, Hamed Kiani and Fagg, Ashton and Huang, Chen and Ramanan, Deva and Lucey, Simon},
  booktitle={2017 IEEE International Conference on Computer Vision (ICCV)}, 
  title={Need for Speed: A Benchmark for Higher Frame Rate Object Tracking}, 
  year={2017},
  volume={},
  number={},
  pages={1134-1143},
  doi={10.1109/ICCV.2017.128}}

@INPROCEEDINGS{10208684,
  author={Held, Jan and Cioppa, Anthony and Giancola, Silvio and Hamdi, Abdullah and Ghanem, Bernard and Van Droogenbroeck, Marc},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={VARS: Video Assistant Referee System for Automated Soccer Decision Making from Multiple Views}, 
  year={2023},
  volume={},
  number={},
  pages={5086-5097},
  doi={10.1109/CVPRW59228.2023.00537}}

@INPROCEEDINGS{9163908,
  author={Nady and Li, Xiang},
  booktitle={2020 Chinese Control And Decision Conference (CCDC)}, 
  title={A Decision-making Model under the Assumption of Insufficient Knowledge and Resource}, 
  year={2020},
  volume={},
  number={},
  pages={4656-4660},
  doi={10.1109/CCDC49329.2020.9163908}}

@INPROCEEDINGS{8806222,
  author={Chen, Zhihao and Khemmar, Redouane and Decoux, Benoit and Atahouet, Amphani and Ertaud, Jean-Yves},
  booktitle={2019 Eighth International Conference on Emerging Security Technologies (EST)}, 
  title={Real Time Object Detection, Tracking, and Distance and Motion Estimation based on Deep Learning: Application to Smart Mobility}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/EST.2019.8806222}}
@INPROCEEDINGS{8959041,
  author={Chaudhury, Subhajit and Kimura, Daiki and Vinayavekhin, Phongtharin and Munawar, Asim and Tachibana, Ryuki and Ito, Koji and Inaba, Yuki and Matsumoto, Minoru and Kidokoro, Shuji and Ozaki, Hiroki},
  booktitle={2019 IEEE International Symposium on Multimedia (ISM)}, 
  title={Unsupervised Temporal Feature Aggregation for Event Detection in Unstructured Sports Videos}, 
  year={2019},
  volume={},
  number={},
  pages={9-97},
  doi={10.1109/ISM46123.2019.00011}}
@INPROCEEDINGS{9413129,
  author={Zita, Aleš and Šroubek, Filip},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={Tracking Fast Moving Objects by Segmentation Network}, 
  year={2021},
  volume={},
  number={},
  pages={10312-10319},
  doi={10.1109/ICPR48806.2021.9413129}}

@Article{s21134550,
AUTHOR = {Brumann, Christopher and Kukuk, Markus and Reinsberger, Claus},
TITLE = {Evaluation of Open-Source and Pre-Trained Deep Convolutional Neural Networks Suitable for Player Detection and Motion Analysis in Squash},
JOURNAL = {Sensors},
VOLUME = {21},
YEAR = {2021},
NUMBER = {13},
ARTICLE-NUMBER = {4550},
URL = {https://www.mdpi.com/1424-8220/21/13/4550},
PubMedID = {34283127},
ISSN = {1424-8220},
ABSTRACT = {In sport science, athlete tracking and motion analysis are essential for monitoring and optimizing training programs, with the goal of increasing success in competition and preventing injury. At present, contact-free, camera-based, multi-athlete detection and tracking have become a reality, mainly due to the advances in machine learning regarding computer vision and, specifically, advances in artificial convolutional neural networks (CNN), used for human pose estimation (HPE-CNN) in image sequences. Sport science in general, as well as coaches and athletes in particular, would greatly benefit from HPE-CNN-based tracking, but the sheer amount of HPE-CNNs available, as well as their complexity, pose a hurdle to the adoption of this new technology. It is unclear how many HPE-CNNs which are available at present are ready to use in out-of-the-box inference to squash, to what extent they allow motion analysis and if detections can easily be used to provide insight to coaches and athletes. Therefore, we conducted a systematic investigation of more than 250 HPE-CNNs. After applying our selection criteria of open-source, pre-trained, state-of-the-art and ready-to-use, five variants of three HPE-CNNs remained, and were evaluated in the context of motion analysis for the racket sport of squash. Specifically, we are interested in detecting player’s feet in videos from a single camera and investigated the detection accuracy of all HPE-CNNs. To that end, we created a ground-truth dataset from publicly available squash videos by developing our own annotation tool and manually labeling frames and events. We present heatmaps, which depict the court floor using a color scale and highlight areas according to the relative time for which a player occupied that location during matchplay. These are used to provide insight into detections. Finally, we created a decision flow chart to help sport scientists, coaches and athletes to decide which HPE-CNN is best for player detection and tracking in a given application scenario.},
DOI = {10.3390/s21134550}
}



@ARTICLE{9784855,
  author={Brumann, C. and Kukuk, M.},
  journal={IEEE Access}, 
  title={Evolution Based Single Camera Resectioning Based on Distance Maps of a Known Geometry for Squash Sports}, 
  year={2022},
  volume={10},
  number={},
  pages={58136-58150},
  doi={10.1109/ACCESS.2022.3178832}}

@online{world-squash-officiating ,
    title = "world squash officiating.",
    url  = "https://worldsquashofficiating.com",
}
@unpublished{upm75832,
          school = {ETSI\_Informatica},
            note = {Unpublished},
           month = {July},
           title = {Deep learning applied to detection, pose estimation, tracking, and birds-eye view in sport videos},
            year = {2023},
          author = {Pinedo de {\'A}ngel, As{\'i}s},
        abstract = {This report covers all the key aspects when developing a project making use of deep learning techniques to sports videos in order to apply detection models, pose estimation, tracking and bird's eye view. 

The documentation begins with the whole process of study and analysis of current systems with similar functionalities and the different techniques and technologies to be applied in the development phase. It then focuses on the explanation of each of the steps necessary for the definition of a processing flow for the videos, with the application of each of the models mentioned above along with some extra functionality.

 Many of the most relevant aspects of a data science project are also defined, such as the methodology to be used, the motivation of the project, its objectives, the planning and a small ethical assessment of the project. 

Evidently, the results obtained are also evaluated, in which we will have both the generated flow and some sample videos in which we will see the performance of the models and their behaviour in general. It is from these results that, once analysed, the conclusions of the project and its development can be drawn.

ABSTRACT

Esta memoria cubre todos los aspectos clave a la hora de desarrollar un proyecto en el que se hace usode de t{\'e}cnicas de Deep Learning para ser aplicar modelos de detecci{\'o}n, seguimiento, estimaci{\'o}n de pose y la vista a{\'e}rea de videos de deportes. 

Esta memoria comienza documentando todo el proceso de estudio y an{\'a}lisis de sistemas con funcionalidades similares junto con las t{\'e}cnicas y tecnolog{\'i}as que han de ser aplicadas en la fase de desarrollo. A continuaci{\'o}n, se centra en la explicaci{\'o}n de cada uno de los pasos necesarios a la hora de definir un flujo de procesado de los videos en el que se aplican cada uno de los modelos mencionados anteriormente junto con alguna funcionalidad extra. 

Tambi{\'e}n se definen muchos de los aspectos mas relevante de un proyecto de ciencia de datos, como son la metodolog{\'i}a a utilizar, la motivaci{\'o}n del proyecto, sus objetivos, la planificaci{\'o}n y una peque{\~n}a valoraci{\'o}n {\'e}tica del mismo. 

Evidentemente tambi{\'e}n se valoran los resultados obtenidos, en los que dispondremos tanto del flujo generado como de algunos videos de muestra en los que veremos el rendimiento de los modelos y su comportamiento en general. De estos resultados es de los cuales una vez analizados, se podr{\'a}n extraer las conclusiones del proyecto y su desarrollo.},
             url = {https://oa.upm.es/75832/}
}
@ARTICLE{Pal2021-re,
  title    = "Deep learning in multi-object detection and tracking: state of
              the art",
  author   = "Pal, Sankar K and Pramanik, Anima and Maiti, J and Mitra, Pabitra",
  abstract = "Object detection and tracking is one of the most important and
              challenging branches in computer vision, and have been widely
              applied in various fields, such as health-care monitoring,
              autonomous driving, anomaly detection, and so on. With the rapid
              development of deep learning (DL) networks and GPU's computing
              power, the performance of object detectors and trackers has been
              greatly improved. To understand the main development status of
              object detection and tracking pipeline thoroughly, in this
              survey, we have critically analyzed the existing DL network-based
              methods of object detection and tracking and described various
              benchmark datasets. This includes the recent development in
              granulated DL models. Primarily, we have provided a comprehensive
              overview of a variety of both generic object detection and
              specific object detection models. We have enlisted various
              comparative results for obtaining the best detector, tracker, and
              their combination. Moreover, we have listed the traditional and
              new applications of object detection and tracking showing its
              developmental trends. Finally, challenging issues, including the
              relevance of granular computing, in the said domain are
              elaborated as a future scope of research, together with some
              concerns. An extensive bibliography is also provided.",
  journal  = "Applied Intelligence",
  volume   =  51,
  number   =  9,
  pages    = "6400--6429",
  month    =  sep,
  year     =  2021
}

@article{Du_2018,
doi = {10.1088/1742-6596/1004/1/012029},
url = {https://dx.doi.org/10.1088/1742-6596/1004/1/012029},
year = {2018},
month = {apr},
publisher = {IOP Publishing},
volume = {1004},
number = {1},
pages = {012029},
author = {Juan Du},
title = {Understanding of Object Detection Based on CNN Family and YOLO},
journal = {Journal of Physics: Conference Series},
abstract = {As a key use of image processing, object detection has boomed along with the unprecedented advancement of Convolutional Neural Network (CNN) and its variants since 2012. When CNN series develops to Faster Region with CNN (R-CNN), the Mean Average Precision (mAP) has reached 76.4, whereas, the Frame Per Second (FPS) of Faster R-CNN remains 5 to 18 which is far slower than the real-time effect. Thus, the most urgent requirement of object detection improvement is to accelerate the speed. Based on the general introduction to the background and the core solution CNN, this paper exhibits one of the best CNN representatives You Only Look Once (YOLO), which breaks through the CNN family’s tradition and innovates a complete new way of solving the object detection with most simple and high efficient way. Its fastest speed has achieved the exciting unparalleled result with FPS 155, and its mAP can also reach up to 78.6, both of which have surpassed the performance of Faster R-CNN greatly. Additionally, compared with the latest most advanced solution, YOLOv2 achieves an excellent tradeoff between speed and accuracy as well as an object detector with strong generalization ability to represent the whole image.}
}



@INPROCEEDINGS{9151039,
  author={Köhl, Philipp and Specker, Andreas and Schumann, Arne and Beyerer, Jürgen},
  booktitle={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={The MTA Dataset for Multi Target Multi Camera Pedestrian Tracking by Weighted Distance Aggregation}, 
  year={2020},
  volume={},
  number={},
  pages={4489-4498},
  doi={10.1109/CVPRW50498.2020.00529}}





@article{HEGAZY2020555,
title = {Online detection and classification of in-corrected played strokes in table tennis using IR depth camera},
journal = {Procedia Computer Science},
volume = {170},
pages = {555-562},
year = {2020},
note = {The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.125},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920305639},
author = {Habiba Hegazy and Mohamed Abdelsalam and Moustafa Hussien and Seif Elmosalamy and Yomna M.I Hassan and Ayman M. Nabil and Ayman Atia},
keywords = {Table tennis, stroke detection, stroke classification, hand gestures, IR depth camera},
abstract = {Table tennis is a complex sport with a distinctive style of play. Due to the rising interest in this sport the past years, attempts have been targeted towards enhancing the training experience and quality through various techniques. Technology has been used to support training sessions for table tennis players before, with a focus on players’ performance measures rather than technique. In this paper, we propose a methodology based on IR depth camera for detecting and classifying the efficiency of strokes performed by players in order to enhance the training experience. Our system is to based on analyzing depth data collected from IR depth camera and recognized using fastDTW algorithm. The results show an average accuracy of 88% - 100%. This is the first paper to address the usage of IR depth camera on the table tennis player to detect and classify the strokes played.}
}
@article{wiimote,
author = {Tahir, Muhammad and Madni, Mustafa and Ziauddin, Sheikh and Awan, Muhammad Arshad and Waqar, Rana Waqar and Khalid, Saher},
year = {2014},
month = {07},
pages = {362-369},
title = {Wiimote Squash: Comparing DTW and WFM Techniques for 3D Gesture Recognition},
volume = {11},
journal = {International Arab Journal of Information Technology}
}
@inproceedings{squashLowCost,
  title={Detection and Tracking of a Fast-Moving Object in Squash using a Low-Cost Approach},
  author={Saumil Sachdeva},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:202774567}
}
@online{Multiple_Cameras,
    title = "ntegrating Multiple Cameras.",
    url  = "https://www.edge-ai-vision.com/2023/09/top-factors-to-consider-when-integrating-multiple-cameras-into-embedded-vision-applications/",
    
}
@online{TechAndHuman,
    title = "Can Tech Really Better Human Decisions In Sports",
    url  = "https://www.forbes.com/sites/forbestechcouncil/2021/11/29/can-tech-really-better-human-decisions-in-sports/?sh=6328c535698d",
    
}
